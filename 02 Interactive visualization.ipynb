{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d3f8d-ecfa-4a4d-81d4-8c5da6daec91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bokeh.io\n",
    "import bokeh.plotting as bpl\n",
    "import cloudpickle as cpkl\n",
    "import fsspec\n",
    "import gzip\n",
    "import itertools as it\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "from pathlib import Path\n",
    "import scipy.sparse as ss\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import thisnotthat as tnt\n",
    "from vectorizers.transformers import CategoricalColumnTransformer, InformationWeightTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2cc85-0cf2-4b75-9d10-51705bf5a047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bokeh.io.output_notebook()\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da83779-4b52-44ee-b1b9-decacfb098a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_vectors = [\"manifest.json\", \"features.npz\", \"map2d.npz\", \"metadata.csv.gz\", \"labels.csv.gz\", \"col2token.pkl.gz\"]\n",
    "if all([Path(f).is_file() for f in files_vectors]):\n",
    "    print(\"Using process map and metadata stored LOCALLY.\")\n",
    "    FS = fsspec.filesystem(\"file\")\n",
    "    ROOT = \".\"\n",
    "else:\n",
    "    print(\"Using CANNED process map and metadata (from Azure container).\")\n",
    "    FS = fsspec.filesystem(\"abfs\", account_name=\"scipy2023\")\n",
    "    ROOT = \"map\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2ec33-e989-4bd6-b400-3faafdf5e737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with FS.open(\"manifest.json\", \"rt\", encoding=\"utf-8\") as file:\n",
    "    manifest = json.load(file)\n",
    "HOST = manifest[\"host\"]\n",
    "DAYS = manifest[\"days\"]\n",
    "print(f\"Context: host {HOST}; days {', '.join(DAYS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d6d194-f207-48ef-86b6-7feaeb6b0fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with FS.open(\"features.npz\", \"rb\") as file_features:\n",
    "    features = ss.load_npz(file_features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b187ae-2ff0-4106-b784-20468e01ae0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with (\n",
    "    FS.open(\"col2token.pkl.gz\", \"rb\") as file_compressed,\n",
    "    gzip.open(file_compressed, \"rb\") as file_pkl\n",
    "):\n",
    "    col2token = dict(enumerate(cpkl.load(file_pkl)))\n",
    "\n",
    "assert len(col2token) == features.shape[1]\n",
    "for i, (k, v) in enumerate(col2token.items()):\n",
    "    if i >= 25:\n",
    "        break\n",
    "    print(k, \":\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139c083-87f7-40c3-8d9a-3cdbf456cfbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with FS.open(\"metadata.csv.gz\", \"rb\") as file_metadata:\n",
    "    metadata = pd.read_csv(file_metadata, parse_dates=[\"timestamp\"], compression=\"gzip\")\n",
    "assert metadata.shape[0] == features.shape[0]\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109ff15-65d7-46f7-bcc0-66abc98b427f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with FS.open(\"labels.csv.gz\", \"rb\") as file_labels:\n",
    "    labels = pd.read_csv(file_labels, compression=\"gzip\")\n",
    "assert labels.shape[0] == features.shape[0]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0936f5-bda8-4ea1-8b1d-d489e4b832f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with FS.open(\"map2d.npz\", \"rb\") as file_vectors:\n",
    "    process_map = np.load(file_vectors)[\"process_map\"]\n",
    "assert process_map.shape == (features.shape[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7882212-16bc-4542-929b-1f30897be147",
   "metadata": {},
   "outputs": [],
   "source": [
    "top15_labels = labels.groupby(\"label\", as_index=False).agg({\"process_id\": \"count\"}).sort_values(\"process_id\", ascending=False).head(15)\n",
    "top15_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7914b6-84e3-4be4-997d-d0d119b19e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_top15 = labels.loc[labels[\"label\"].isin(set(top15_labels[\"label\"]))].copy()\n",
    "indices_top15 = labels_top15.index.copy()\n",
    "labels_top15.reset_index(drop=True, inplace=True)\n",
    "labels_top15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb22a2-2dbf-4e96-90e4-8af7faef020d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processes_top15 = process_map[indices_top15, :]\n",
    "features_top15 = features[indices_top15, :]\n",
    "metadata_top15 = metadata.loc[indices_top15].copy()\n",
    "processes_top15.shape, features_top15.shape, metadata_top15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c497d40-2b67-448c-98da-23a64f8886a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseSupportSummarizer:\n",
    "    \"\"\"\n",
    "    Summarizer for a DataSummaryPane.\n",
    "    This takes a sparse matrix of counts or importances.  Then for any selection of data it computes the\n",
    "    column marginals of that matrix and finds the columns with the largest marginals.\n",
    "\n",
    "    It returns a DataFrame with the top max_features features along with their column marginals and support.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    matrix: a sparse matrix\n",
    "        This is the matrix which we will use for computing the marginals\n",
    "    column_index_dictionary: dict\n",
    "         A dictionary mapping from column indices to column names\n",
    "    max_features: int <default: 10>\n",
    "        The number of features to return\n",
    "    proportional_support: bool <default: True>\n",
    "        Should the proportion be normalized (True) or left as a raw count (False)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        matrix,\n",
    "        column_index_dictionary,\n",
    "        max_features= 10,\n",
    "        proportional_support = True\n",
    "    ):\n",
    "        self.matrix = matrix\n",
    "        self.column_index_dictionary = column_index_dictionary\n",
    "        self.max_features = max_features\n",
    "        self.proportional_support = proportional_support\n",
    "\n",
    "    def summarize(self, selected):\n",
    "        data = self.matrix[plot.selected,:]\n",
    "        column_marginal = np.array(data.sum(axis=0)).squeeze()\n",
    "        largest_indices = np.argsort(column_marginal)[::-1][:self.max_features]\n",
    "        features = [self.column_index_dictionary[x] for x in largest_indices]\n",
    "        kinds, values = zip(*features)\n",
    "        importance = column_marginal[largest_indices]\n",
    "        support = np.sort(np.array((data>0).sum(axis=0)).squeeze())[::-1][:self.max_features]\n",
    "        if self.proportional_support:\n",
    "            support = support / data.shape[0]\n",
    "        return pd.DataFrame({'Kind': kinds, 'Value': values, 'Total weight':importance, 'support':support})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c769c79-1c3b-4733-a0cd-10c707cfc084",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseFeatureImportanceSummarizer:\n",
    "    \"\"\"\n",
    "    Summarizer for the PlotSummaryPane that constructs a class balanced, L1 penalized,\n",
    "    logistic regression between the selected points and the remaining data.\n",
    "\n",
    "    This version takes a sparse feature matrix and column_index_dictionary which maps from the\n",
    "    indices of the matrix to the set of feature names.\n",
    "\n",
    "    Then it displays that feature importance in a bar plot.\n",
    "    The title is colour coded by model accuracy in order to give a rough approximation of\n",
    "    how much trust you should put in the model.\n",
    "\n",
    "    All of the standard caveats with using the coefficients of a linear model as a feature\n",
    "    importance measure should be included here.\n",
    "\n",
    "    It might be worth reading the sklearn documentation on the\n",
    "    common pitfalls in the interpretation of coefficients of linear models\n",
    "    (https://scikit-learn.org/stable/auto_examples/inspection/plot_linear_model_coefficient_interpretation.html)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data: sparse_matrix\n",
    "        A sparse_matrix corresponding to the plot points.\n",
    "    column_index_dictionary: dict\n",
    "        A dictionary mapping from column indices to column names\n",
    "    max_features: int <default: 15>\n",
    "        The maximum number of features to display the importance for.\n",
    "    tol_importance_relative: float <default: 0.01>\n",
    "        The minimum feature coefficient value in order to be considered important.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        column_index_dictionary,\n",
    "        max_features: int = 15,\n",
    "        tol_importance_relative: float = 0.01,\n",
    "    ):\n",
    "\n",
    "        self.data = data  # Indexed 0 to length.\n",
    "        self.max_features = max_features\n",
    "        self.tol_importance_relative = tol_importance_relative\n",
    "        self._features = column_index_dictionary\n",
    "        self._classifier = None\n",
    "        self._classes = None\n",
    "\n",
    "    def summarize(self, selected, width: int = 600, height: int = 600):\n",
    "        classes = np.zeros((self.data.shape[0],), dtype=\"int32\")\n",
    "        classes[selected] = True\n",
    "        classifier = LogisticRegression(\n",
    "            penalty=\"l1\",\n",
    "            solver=\"liblinear\",\n",
    "            class_weight=\"balanced\",\n",
    "            tol=1e-3,\n",
    "            max_iter=20\n",
    "        ).fit(self.data, classes)\n",
    "        self._classifier = classifier\n",
    "        self._classes = classes\n",
    "        assert classifier.coef_.shape[0] == 1 or classifier.coef_.ndim == 1\n",
    "        importance = np.squeeze(classifier.coef_)\n",
    "        index_importance = np.argsort(-np.abs(importance))[: self.max_features]\n",
    "        importance_abs = np.abs(importance)[index_importance]\n",
    "        importance_relative = importance_abs / np.max(importance_abs)\n",
    "        importance_restricted = importance[\n",
    "            np.where(importance_relative > self.tol_importance_relative)\n",
    "        ]\n",
    "\n",
    "        selected_columns_tuples = [self._features[x] for x in index_importance[: len(importance_restricted)] ]\n",
    "        selected_columns = [f\"{kind}: {value}\" for kind, value in selected_columns_tuples]\n",
    "\n",
    "        model_acc = classifier.score(self.data, classes)\n",
    "        fig = bpl.figure(\n",
    "            y_range=selected_columns,\n",
    "            width=width,\n",
    "            height=height,\n",
    "        )\n",
    "        if model_acc > 0.9:\n",
    "            fig.title = f\"Estimated Feature Importance\\nTrustworthiness high ({model_acc:.4} mean accuracy)\"\n",
    "            fig.title.text_color = \"green\"\n",
    "        elif model_acc > 0.8:\n",
    "            fig.title = f\"Estimated Feature Importance\\nTrustworthiness medium ({model_acc:.4} mean accuracy)\"\n",
    "            fig.title.text_color = \"yellow\"\n",
    "        elif model_acc > 0.5:\n",
    "            fig.title = f\"Estimated Feature Importance\\nTrustworthiness low ({model_acc:.4} mean accuracy)\"\n",
    "            fig.title.text_color = \"orange\"\n",
    "        else:\n",
    "            fig.title = f\"Estimated Feature Importance\\nTrustworthiness low ({model_acc:.4} mean accuracy)\"\n",
    "            fig.title.text_color = \"red\"\n",
    "\n",
    "        fig.hbar(\n",
    "            y=selected_columns,\n",
    "            right=importance[index_importance[: len(importance_restricted)]],\n",
    "            height=0.8,\n",
    "        )\n",
    "        plt.xlabel(\"Coefficient values corrected by the feature's std dev\")\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1766a56a-490b-47a4-bcfd-659f87dae406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infoweight = InformationWeightTransformer().fit_transform(features_top15).astype(np.float32)\n",
    "infoweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090a18d-8809-4ebc-9877-522ea28ff3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_top15.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d5113-1331-4488-95f2-172e87435584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_27.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c847eb-71ee-418e-b3b3-3f6667764360",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metadata_summary_top15 = pd.merge(\n",
    "    metadata_top15,\n",
    "    CategoricalColumnTransformer(\n",
    "        object_column_name='process_id',\n",
    "        descriptor_column_name=list(metadata_top15.columns[2:]),\n",
    "        include_column_name=True\n",
    "    ).fit_transform(metadata_top15.astype('str')).rename(\"event_summary\").reset_index(),\n",
    "    on=\"process_id\",\n",
    "    how=\"left\"\n",
    ").merge(labels_top15, on=\"process_id\", how=\"left\")\n",
    "metadata_summary_top15[\"event_summary_string\"] = metadata_summary_top15[\"event_summary\"].apply(lambda x: \"<br>\".join(x))\n",
    "metadata_summary_top15[\"freq\"] = 1\n",
    "metadata_summary_top15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b304fc-3167-4821-b8ba-af7743135dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths_short = {i: (kind, value.split(\"\\\\\")[-1]) for i, (kind, value) in col2token.items()}\n",
    "assert len(paths_short) == features.shape[1]\n",
    "for i, (k, v) in enumerate(paths_short.items()):\n",
    "    if i >= 25:\n",
    "        break\n",
    "    print(k, \":\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811c5b2-b8df-4589-8eb4-9c840ff0f9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "infoweight_compressed = TruncatedSVD(n_components=1024).fit_transform(infoweight)\n",
    "infoweight_compressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0f522-6d91-4a69-a338-4edbb6f9d82b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "layer_metadata = tnt.SparseMetadataLabelLayers(\n",
    "    infoweight_compressed,\n",
    "    processes_top15,\n",
    "    features_top15,\n",
    "    {i: value for i, (_, value) in paths_short.items()},\n",
    "    cluster_map_representation=False,\n",
    "    random_state=42\n",
    ")\n",
    "layer_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bddc98a-a850-49e5-a7d6-9d626063b45a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template_info_process = \"\"\"\n",
    "# {label}\n",
    "\n",
    "## {process_id}\n",
    "\n",
    "---\n",
    "\n",
    "{event_summary_string}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfbf3d-eada-4e7f-8d3d-83ff4c09a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = tnt.BokehPlotPane(\n",
    "    processes_top15,\n",
    "    labels=labels_top15[\"label\"],\n",
    "    width=600,\n",
    "    height=600,\n",
    "    show_legend=False,\n",
    "    tools=\"pan,wheel_zoom,lasso_select,tap,reset\"\n",
    ")\n",
    "plot.add_cluster_labels(layer_metadata, max_text_size=24)\n",
    "\n",
    "editor = tnt.LabelEditorWidget(plot.labels, selectable_legend=True)\n",
    "editor.link_to_plot(plot)\n",
    "\n",
    "#This is one of our most simple search widgets.  Please see our read the docs page for more powerful and flexible search options.\n",
    "search = tnt.KeywordSearchWidget(labels_top15[\"label\"])\n",
    "search.link_to_plot(plot)\n",
    "\n",
    "info_pane = tnt.InformationPane(metadata_summary_top15, markdown_template=template_info_process, width=600)\n",
    "info_pane.link_to_plot(plot)\n",
    "\n",
    "value_summarizer = tnt.summary.dataframe.ValueCountsSummarizer(labels_top15[\"label\"])\n",
    "value_summary_plot = tnt.summary.dataframe.DataSummaryPane(value_summarizer)\n",
    "value_summary_plot.link_to_plot(plot)\n",
    "\n",
    "time_summarizer = tnt.summary.plot.TimeSeriesSummarizer(\n",
    "    metadata_summary_top15,\n",
    "    time_column='timestamp',\n",
    "    count_column='freq'\n",
    ")\n",
    "time_summary_plot = tnt.summary.plot.PlotSummaryPane(time_summarizer)\n",
    "time_summary_plot.link_to_plot(plot)\n",
    "\n",
    "control_df = metadata_top15[\"THREAD,FLOW,PROCESS,FILE,REGISTRY,TASK,MODULE,USER_SESSION,SERVICE,SHELL,HOST\".split(',')]\n",
    "control = tnt.PlotControlWidget(raw_dataframe=control_df)\n",
    "control.link_to_plot(plot)\n",
    "\n",
    "support_summarizer = SparseSupportSummarizer(features_top15, paths_short, max_features=16)\n",
    "support_summary_df = tnt.summary.dataframe.DataSummaryPane(support_summarizer, width=600, sizing_mode=None)\n",
    "support_summary_df.link_to_plot(plot)\n",
    "\n",
    "feature_summarizer = SparseFeatureImportanceSummarizer(features_top15, paths_short, max_features=8)\n",
    "feature_summary_plot = tnt.summary.plot.PlotSummaryPane(feature_summarizer, width=800, sizing_mode=\"stretch_both\")\n",
    "feature_summary_plot.link_to_plot(plot)\n",
    "\n",
    "#Lay out the widgets that you are interested in using via Panels excellent Row, Column and Tab functions\n",
    "pn.Column(\n",
    "    pn.Row(plot, pn.Column(pn.Row(editor, pn.Column(search, control)))),\n",
    "    pn.Tabs(\n",
    "        (\"Chronology\", pn.Row(time_summary_plot, value_summary_plot)),\n",
    "        (\"Feature importance\", pn.Row(feature_summary_plot, support_summary_df)),\n",
    "        (\"Details\", info_pane))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef76126-95ae-4f94-a0f4-aaf5d6bbceee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scipy 2023",
   "language": "python",
   "name": "scipy2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
