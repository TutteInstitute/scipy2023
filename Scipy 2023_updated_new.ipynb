{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c9c51c3-8d38-42c2-97db-158916fea344",
   "metadata": {},
   "source": [
    "All text annotations are temporary, and for guiding John."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6508a1-2485-49a0-910f-3f60fc97502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.io\n",
    "from collections import defaultdict\n",
    "from dask import delayed\n",
    "from dask.distributed import LocalCluster, Client, as_completed\n",
    "import gzip\n",
    "from hashlib import md5\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "from pathlib import Path\n",
    "import scipy.sparse as ss\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import struct\n",
    "import sys\n",
    "import thisnotthat as tnt\n",
    "from tqdm.auto import tqdm\n",
    "import umap\n",
    "import vectorizers as vz\n",
    "import vectorizers.transformers as vzt\n",
    "from vectorizers.transformers import CategoricalColumnTransformer\n",
    "import zstandard as zstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88b19b-386f-4f43-af57-7988acc7bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.output_notebook()\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f485889-a8d6-4486-a0f3-14e1085ff7c7",
   "metadata": {},
   "source": [
    "Dask makes things go zzzzzoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eca4c1-a9f4-4dd6-ba49-f7c476f6d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bac1c3-7e99-4262-ac59-96f675692808",
   "metadata": {},
   "source": [
    "We will work on host 501, processing all days. One can also choose days between 18 and 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e614f-15da-4531-a3ef-596bdf55a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = 501\n",
    "DAYS = [\"*\"]\n",
    "HOSTNAME = f\"SysClient{HOST:04d}.systemia.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6f6be7-1d2a-4752-9f20-1bc8bc77ac52",
   "metadata": {},
   "source": [
    "The data lives as compressed JSON-lines chunks, Zstd-compressed. The following data engineering goes much less deep into token generation than the work we presented so far, so as to put the emphasis on the vectorization (not the data engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3e552-ddb2-4ed6-a7a6-f598a7e9f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas = {\n",
    "    \"FLOW\": [\"object\", \"action\", (\"src_ip\", \"ip\"), (\"dest_ip\", \"ip\"), (\"src_port\", \"port\"), (\"dest_port\", \"port\"), \"l4protocol\", \"direction\"],\n",
    "    \"FILE\": [\"object\", \"action\", (\"file_path\", \"path\"), \"info_class\", (\"new_path\", \"path\")],\n",
    "    \"HOST\": [\"object\", \"action\"],\n",
    "    \"MODULE\": [\"object\", \"action\", (\"module_path\", \"path\")],\n",
    "    \"REGISTRY\": [\"object\", \"action\", (\"key\", \"registry-key\"), (\"value\", \"registry-value\"), (\"type\", \"registry-type\")],\n",
    "    \"SERVICE\": [\"object\", \"action\", (\"name\", \"service-name\")],\n",
    "    \"SHELL\": [\"object\", \"action\"],\n",
    "    \"TASK\": [\"object\", \"action\", \"path\", (\"task_name\", \"task-name\")],\n",
    "    \"THREAD\": [\"object\", \"action\"],\n",
    "    \"USER_SESSION\": [\"object\", \"action\", (\"user\", \"user-domain\"), (\"requesting_domain\", \"domain\"), (\"requesting_user\", \"user\"), (\"src_ip\", \"ip\"), (\"src_port\", \"port\")],\n",
    "    \"PROCESS\": {\n",
    "        \"CREATE\": {\n",
    "            \"actorID\": [\"object\", \"action\", (\"image_path\", \"child\"), (\"image_path\", \"path\")],\n",
    "            \"objectID\": [(\"parent_image_path\", \"parent\"), (\"image_path\", \"process\"), (\"user\", \"user-domain\")]\n",
    "        },\n",
    "        \"OPEN\": {\n",
    "            \"actorID\": [\"object\", \"action\"]\n",
    "        },\n",
    "        \"TERMINATE\": {\n",
    "            \"actorID\": [\"object\", \"action\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d68368-9fec-4256-a7e9-7ccf558218c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_events(path_chunk):\n",
    "    with zstd.open(path_chunk, mode=\"rt\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                # Skip ill-formed records.\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf9de4-8938-47b2-b66c-428f3dafb952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(path_chunk):\n",
    "    for event in iter_events(path_chunk):\n",
    "        obj = event[\"object\"]\n",
    "        if obj not in schemas:\n",
    "            continue\n",
    "        schema = (\n",
    "            schemas[obj].get(event[\"action\"], {})\n",
    "            if isinstance(schemas[obj], dict)\n",
    "            else {\"actorID\": schemas[obj]}\n",
    "        )\n",
    "        for identifier, features in schema.items():\n",
    "            tokens = []\n",
    "            for feature in features:\n",
    "                field, kind = (feature, feature) if isinstance(feature, str) else feature\n",
    "                if value := event.get(field, \"\"):\n",
    "                    tokens.append((kind, value))\n",
    "            yield (pd.Timestamp(event[\"timestamp\"]), event[identifier], tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9668846d-1895-4bf1-b7fb-1e6fe6d103d2",
   "metadata": {},
   "source": [
    "Given a data chunk, we return a data frame where its categorical tokens are already in the list form suitable for one-hot vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19459d00-01ed-4e82-8f8a-b66dad70f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_features(path_chunk):\n",
    "    return pd.DataFrame(\n",
    "        data=extract_features(path_chunk),\n",
    "        columns=[\"timestamp\", \"process_id\", \"tokens\"]\n",
    "    ).astype({\"process_id\": \"category\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002d84f-838c-4b91-b737-8b5beef2bff3",
   "metadata": {},
   "source": [
    "Where are my data chunks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402e9e4-9f18-4c1d-8785-4d496ef347df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_HOSTNAME = Path(\"/data/optc/scipy2023\") / HOSTNAME\n",
    "CHUNKS = sorted(sum(\n",
    "    [list(ROOT_HOSTNAME.glob(f\"{day}/optc-eng.*.json.zstd\")) for day in DAYS],\n",
    "    []\n",
    "))\n",
    "len(CHUNKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bececc9-399b-4eb5-91ea-4c0424072eec",
   "metadata": {},
   "source": [
    "The vectorization gambit is to do it by chunks, and combine the resulting sparse matrices afterwards, using nifty NgramVectorizer addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3fb560-8114-416c-bfc2-d422d2ed472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_features(path_chunk):\n",
    "    return vz.NgramVectorizer().fit(tabulate_features(path_chunk)[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a48713-a582-4888-a45e-18da377d632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "summands = [[delayed(vectorize_features)(chunk) for chunk in CHUNKS]]\n",
    "while len(summands[-1]) > 1:\n",
    "    to_sum = summands[-1]\n",
    "    sums = []\n",
    "    for i in range(0, len(to_sum), 2):\n",
    "        if i + 1 < len(to_sum):\n",
    "            sums.append(to_sum[i] + to_sum[i + 1])\n",
    "        else:\n",
    "            sums.append(to_sum[i])\n",
    "    summands.append(sums)\n",
    "\n",
    "futs = client.compute(sum(summands, []))\n",
    "for fut in tqdm(as_completed(futs), total=sum(len(ss) for ss in summands)):\n",
    "    pass\n",
    "\n",
    "vzr_all = futs[-1].result()\n",
    "event_matrix = vzr_all._train_matrix\n",
    "event_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11fc4cd-96b7-436e-be07-80941c14c1c3",
   "metadata": {},
   "source": [
    "Let's now group events by process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99afee-669d-4178-a27b-e869fb263422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_processes(metadata):\n",
    "    return metadata.groupby(\"process_id\", as_index=False).agg({\"timestamp\": \"min\", **{col: \"sum\" for col in metadata.columns if col not in {\"timestamp\", \"process_id\"}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6242f3-d59a-4d6c-b639-73450269138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_by_process(path_chunk):\n",
    "    features = tabulate_features(path_chunk)\n",
    "    metadata = features[[\"timestamp\", \"process_id\"]].join(\n",
    "        pd.DataFrame(\n",
    "            data=iter(features[\"tokens\"].apply(lambda tokens: {value: 1.0 for kind, value in tokens if kind == \"object\"}))\n",
    "        ),\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    metadata[\"event_index\"] = pd.Series(metadata.index).apply(lambda x: [x])\n",
    "    return summarize_processes(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb95456-5ec2-4463-a277-5bf166efd7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "events_by_process(CHUNKS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d064f52-44a6-46da-86bd-56db4afddaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "process2ievent = {}\n",
    "total_events = 0\n",
    "metadata_processes = pd.DataFrame()\n",
    "for fut in tqdm(client.map(events_by_process, CHUNKS), total=len(CHUNKS)):\n",
    "    processes = fut.result()\n",
    "    metadata_processes = summarize_processes(pd.concat([metadata_processes, processes.drop(columns=[\"event_index\"])], ignore_index=True).fillna(0.0))\n",
    "    for process_id, indices in processes[[\"process_id\", \"event_index\"]].itertuples(index=False):\n",
    "        process2ievent.setdefault(process_id, [])\n",
    "        for index_row_chunk in indices:\n",
    "            process2ievent[process_id].append(index_row_chunk + total_events)\n",
    "    total_events += processes[\"event_index\"].apply(len).sum()\n",
    "\n",
    "len(process2ievent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2c32a-8ae4-48dd-884f-933af590f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd99162-a160-41d5-9bb2-4f44919a2ad5",
   "metadata": {},
   "source": [
    "That's a *lot* of processes. Let's prune off those for which we don't have enough features (by weight) to reliably describe their behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c74f8-e846-451e-b8cb-2bfcdbe3b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_per_event = np.array(event_matrix.sum(axis=1)).squeeze()\n",
    "features_per_process = pd.Series({process_id: sum([features_per_event[i] for i in indices]) for process_id, indices in tqdm(process2ievent.items())})\n",
    "features_per_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87428c49-b604-4624-98a4-0d5eaaf3296a",
   "metadata": {},
   "source": [
    "Distribution of number of features per process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0024d20-620e-47ff-b22a-64a07c846304",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_per_process.apply(np.log10).hist(bins=range(-1, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1cd962-583e-4c21-8aaa-78735e6bb9a1",
   "metadata": {},
   "source": [
    "It does not make much sense to me to keep processes described by a total number of categorical features less than 10. So let's drop the guys from the first column.\n",
    "\n",
    "We will do that while also putting together process vectors by summing event vectors.\n",
    "This means a linear combination of the rows of the event matrix.\n",
    "The fastest way of achieving that is by computing a projection matrix that we will multiply on the left of the event matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831928a2-25f4-4c06-88ad-aef607ef3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "irows = []\n",
    "icols = []\n",
    "process2irow = {}\n",
    "irow2process = {}\n",
    "irow_next = 0\n",
    "for process_id, indices in tqdm(process2ievent.items()):\n",
    "    if features_per_process.loc[process_id] >= 10:\n",
    "        irow = irow_next\n",
    "        irow_next += 1\n",
    "        irows += [irow] * len(indices)\n",
    "        icols += indices\n",
    "        process2irow[process_id] = irow\n",
    "        irow2process[irow] = process_id\n",
    "\n",
    "projection = ss.coo_matrix((np.ones((len(irows),), dtype=np.int32), (irows, icols)), shape=(len(process2irow), event_matrix.shape[0])).tocsr()\n",
    "assert set(np.array(projection.sum(axis=0)).squeeze()) <= {0, 1}\n",
    "projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e2689-fbaf-440f-ba77-aae450f31514",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_matrix = (projection @ event_matrix).astype(np.float32)\n",
    "process_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8cb25-8f73-420e-9848-8ef4a2124a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned = sorted(list(irow2process.items()))\n",
    "metadata_pruned = metadata_processes.set_index(\"process_id\").loc[[process_id for _, process_id in pruned]].copy().reset_index()\n",
    "assert pd.Series(metadata_pruned.index).equals(pd.Series([i for i, _ in pruned]))\n",
    "metadata_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775a87d-ffd3-43de-8aac-eab06b8e53a4",
   "metadata": {},
   "source": [
    "The categories (_labels_) for our process instances are either the command line by which they were started, or when we can't find that, their related image path.\n",
    "The former can only be found in `PROCESS-CREATE` events.\n",
    "The latter is field common to all events, and its value should be shared by all events generated by any given process instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1a285-bc90-4354-ba43-a6ee89b79dd5",
   "metadata": {},
   "source": [
    "The way we associate labels to process instances is thus to extract the best label we can from every event.\n",
    "We then tabulate these in association with their process ID, and use an *importance* ordinal to denote which label should take precedence.\n",
    "We sort this table by importance, and drop process ID duplicates: what remains are the best guest we can take as label for every process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b555c-78da-4a44-8643-a285c8ffcefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_labels(proposals):\n",
    "    return proposals.sort_values(\"importance\", ascending=True).drop_duplicates(subset=[\"process_id\"], keep=\"first\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9736c95-b448-4a1e-9787-1cf3a75922f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_processes(path_chunk):\n",
    "    data = []\n",
    "    for event in iter_events(path_chunk):\n",
    "        if event[\"object\"] == \"PROCESS\" and event[\"action\"] == \"CREATE\":\n",
    "            if command_line := event.get(\"command_line\", \"\"):\n",
    "                data.append((event[\"objectID\"], 0, command_line))\n",
    "            elif image_path := event.get(\"image_path\", \"\"):\n",
    "                data.append((event[\"objectID\"], 10, image_path))\n",
    "            if parent_image_path := event.get(\"parent_image_path\", \"\"):\n",
    "                data.append((event[\"actorID\"], 10, parent_image_path))\n",
    "        else:\n",
    "            if image_path := event.get(\"image_path\", \"\"):\n",
    "                data.append((event[\"actorID\"], 10, image_path))\n",
    "\n",
    "    return filter_labels(pd.DataFrame(data=data, columns=[\"process_id\", \"importance\", \"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6e75dc-c612-453f-900c-b4660e800730",
   "metadata": {},
   "source": [
    "We then run this filtering iteratively across best proposals from every chunk, and come out the other end with every process instance labeled... or nearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f505ad-4c31-4fb0-83c5-d3232e40b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_known = pd.DataFrame()\n",
    "for fut in tqdm(client.map(label_processes, CHUNKS), total=len(CHUNKS)):\n",
    "    labels_known = filter_labels(pd.concat([labels_known, fut.result()], ignore_index=True))\n",
    "labels_known"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a4c2a4-d02a-4980-9169-008a2072ed17",
   "metadata": {},
   "source": [
    "Any process missing a label, now, we just consider we **don't know** what they are about.\n",
    "Let's bin these together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f5f2a-83ce-438f-9f0a-3f720f4230cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.Series(irow2process, name=\"process_id\").to_frame().merge(labels_known[[\"process_id\", \"label\"]], on=\"process_id\", how=\"left\").fillna(\"(unknown)\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84ecb16-4b39-4d6e-beb7-498b150fbeae",
   "metadata": {},
   "source": [
    "Now, not all features are _useful_ for characterizing the process instances.\n",
    "*Orphan features* are too few for their sharing to denote similarity between more than a very small group of processes.\n",
    "*Spurious features* are too often associated to processes to help differentiate between them (like stop words).\n",
    "So a quick thresholding might help compress our very large feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835f399-528a-42c5-b4f8-57578a583c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.Series(np.array(process_matrix.sum(axis=0)).squeeze())\n",
    "sum(feature_importance == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d93937-640d-475c-b72e-020bccd7eb86",
   "metadata": {},
   "source": [
    "So, the pruning of the set of processes already leaves 41 features completely useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d88cdd-b3d6-40bb-85fc-c6402f261234",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.loc[feature_importance > 0].apply(np.log10).hist(bins=[-2,-1,0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7241dc-210e-449f-be4c-8166a44fceab",
   "metadata": {},
   "source": [
    "Most features, by a large factor, are orphans; we seem not to have any spurious feature, as none is associated to more than 10000 process instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bd8993-c4bd-461f-bda8-9d947df300be",
   "metadata": {},
   "source": [
    "Let's take a more detailed look at the first column of the previous histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2283a-a87e-4d3e-b014-3e47091bbdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.loc[feature_importance < 10].hist(bins=np.linspace(0, 10, 10) - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748a013c-98ff-4a92-afb1-833fa05a0b4e",
   "metadata": {},
   "source": [
    "Again, most of these rarely used features are literal orphans: associated to one or two processes.\n",
    "Let's cut off any that's not tied to at least 3 processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae0219-a0eb-4664-84f6-cdc1486729fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "col2token = []\n",
    "token2col = {}\n",
    "indices_keep = []\n",
    "for i, count in enumerate(feature_importance):\n",
    "    if count > 3:\n",
    "        indices_keep.append(i)\n",
    "        token = vzr_all.column_index_dictionary_[i]\n",
    "        index_new = len(col2token)\n",
    "        col2token.append(token)\n",
    "        token2col[token] = index_new\n",
    "\n",
    "reduced_matrix = process_matrix[:, indices_keep].copy()\n",
    "reduced_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68043021-80bf-4382-b961-9c97d49285ad",
   "metadata": {},
   "source": [
    "Ok, has this feature space reduction killed the representation of processes?\n",
    "I'm hoping the total feature weight for any process is at least 5 (e.g. 5 tokens associated to it across all events that characterize it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf327c-746a-442f-9e94-0ddc3463a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_per_process_redux = np.array(reduced_matrix.sum(axis=1)).squeeze()\n",
    "assert np.min(features_per_process_redux) > 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46f115-3a86-4ad5-805e-e301f39f6041",
   "metadata": {},
   "source": [
    "Now, it's always easier to compute the compressed vector representation on the subset of unique process vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fcac53-cbe8-400c-ad8d-03e0c9cdd014",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def md5_list(it):\n",
    "    return struct.unpack(\"<QQ\", md5(memoryview(np.array(it))).digest())\n",
    "\n",
    "reduced_lil = reduced_matrix.tolil()\n",
    "hh = np.zeros(shape=(reduced_matrix.shape[0], 4), dtype=np.uint64)\n",
    "for i, indices_values in enumerate(zip(reduced_lil.rows, reduced_lil.data)):\n",
    "    hh[i, :] = sum((md5_list(it) for it in indices_values), ())\n",
    "_, index_u, inverse_u, counts_u = np.unique(hh, axis=0, return_index=True, return_inverse=True, return_counts=True)\n",
    "index_u.shape, inverse_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4df7f3-aa2a-4491-b998-2b1a8775dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_matrix = reduced_matrix[index_u, :]\n",
    "unique_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f02e10-1e36-4a23-97a8-dd6806385a77",
   "metadata": {},
   "source": [
    "I have tried running the information weight transform on the matrix of unique process vectors,\n",
    "but the result seems to confuse UMAP **a lot**.\n",
    "UMAP would crash on that matrix by putting way too many vectors under one particular leaf of the RP tree:\n",
    "Leland mused that the hyperplanes used to spread the vectors between the RP trees were doing a poor job.\n",
    "I didn't have the time to truly debug this, so I moved on with directly compressing the matrix of unique process vectors."
   ]
  },
  {
   "cell_type": "raw",
   "id": "84d058a3-1af8-45a5-b177-ae4d425b0d46",
   "metadata": {},
   "source": [
    "%%time\n",
    "normalized_matrix = Normalizer(norm=\"l1\").fit_transform(unique_matrix)\n",
    "normalized_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5f526ce-75e8-48df-9979-4ad37de2a1e1",
   "metadata": {},
   "source": [
    "%%time\n",
    "infoweight_matrix = vzt.InformationWeightTransformer().fit_transform(normalized_matrix).astype(np.float32)\n",
    "infoweight_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432da390-3cf1-46d3-b622-c1c343977b69",
   "metadata": {},
   "source": [
    "The protomap only contains the unique vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb2911-1da4-4e86-bd8b-04839b85269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "process_protomap = umap.UMAP(n_components=2, metric=\"cosine\", densmap=True, dens_lambda=4, n_epochs=800, verbose=True).fit_transform(Normalizer(norm=\"l1\").fit_transform(unique_matrix))\n",
    "process_protomap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1927e5-a4b8-40cc-b796-e1dbbecbb09e",
   "metadata": {},
   "source": [
    "The full map is the protomap reduplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2b20b-0c6f-4808-b2d4-f0ed23511a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_map = process_protomap[inverse_u, :]\n",
    "process_map.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806eae98-4842-4a9d-afc9-c8a516b53cdc",
   "metadata": {},
   "source": [
    "The following will visualize a map of all process instances, where we color the most frequent process classes (top 12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce371c-1e82-4d5e-a21c-dddb45384c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processes_top12 = labels.groupby(\"label\", as_index=False).agg({\"process_id\": \"count\"}).sort_values(\"process_id\", ascending=False).head(12)\n",
    "processes_top12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e192b7-0268-4ede-b729-72e5addb5a9a",
   "metadata": {},
   "source": [
    "### Build some custom summarizers\n",
    "ThisNotThat hasn't yet integrated a few of the data summarization views that we'd like to use to explore our data.  As such we'll build them ourselves for the moment.  Once they prove generally useful we'll contribute them back to the ThisNotThat project via a pull request. That will allow our work to be used by both ourselves and others in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629ecfc-a1a5-4fc3-9a44-64c60bcc7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(*[(0, 3), (1, 2), (3, 4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ea2c6-a426-4850-9752-8aeb5178b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseSupportSummarizer:\n",
    "    \"\"\"\n",
    "    Summarizer for a DataSummaryPane.\n",
    "    This takes a sparse matrix of counts or importances.  Then for any selection of data it computes the\n",
    "    column marginals of that matrix and finds the columns with the largest marginals.\n",
    "\n",
    "    It returns a DataFrame with the top max_features features along with their column marginals and support.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    matrix: a sparse matrix\n",
    "        This is the matrix which we will use for computing the marginals\n",
    "    column_index_dictionary: dict\n",
    "         A dictionary mapping from column indices to column names\n",
    "    max_features: int <default: 10>\n",
    "        The number of features to return\n",
    "    proportional_support: bool <default: True>\n",
    "        Should the proportion be normalized (True) or left as a raw count (False)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        matrix,\n",
    "        column_index_dictionary,\n",
    "        max_features= 10,\n",
    "        proportional_support = True\n",
    "    ):\n",
    "        self.matrix = matrix\n",
    "        self.column_index_dictionary = column_index_dictionary\n",
    "        self.max_features = max_features\n",
    "        self.proportional_support = proportional_support\n",
    "\n",
    "    def summarize(self, selected):\n",
    "        data = self.matrix[plot.selected,:]\n",
    "        column_marginal = np.array(data.sum(axis=0)).squeeze()\n",
    "        largest_indices = np.argsort(column_marginal)[::-1][:self.max_features]\n",
    "        features = [self.column_index_dictionary[x] for x in largest_indices]\n",
    "        kinds, values = zip(*features)\n",
    "        importance = column_marginal[largest_indices]\n",
    "        support = np.sort(np.array((data>0).sum(axis=0)).squeeze())[::-1][:self.max_features]\n",
    "        if self.proportional_support:\n",
    "            support = support / data.shape[0]\n",
    "        return pd.DataFrame({'Kind': kinds, 'Value': values, 'Total weight':importance, 'support':support})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "666f69da-1c20-4e57-a4f8-591f25282b06",
   "metadata": {},
   "source": [
    "data = sparse_features_top12_only[:5, :]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b7f2b3d-e2f3-4d51-b44e-780f41e817c2",
   "metadata": {},
   "source": [
    "column_marginal = np.array(data.sum(axis=0)).squeeze()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70a8927d-5dc2-4260-980f-ae96cc51654b",
   "metadata": {},
   "source": [
    "largest_indices = np.argsort(column_marginal)[::-1][:10]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "333b6484-01a6-4542-8326-df3ce9f58a08",
   "metadata": {},
   "source": [
    "features = [column_index_dictionary[x] for x in largest_indices]\n",
    "features"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9252ead9-fe57-4f06-a1d3-f903709e0bd7",
   "metadata": {},
   "source": [
    "kinds, values = zip(*features)\n",
    "importance = column_marginal[largest_indices]\n",
    "support = np.sort(np.array((data>0).sum(axis=0)).squeeze())[::-1][:self.max_features]\n",
    "if self.proportional_support:\n",
    "    support = support / data.shape[0]\n",
    "return pd.DataFrame({'kind': kinds, 'value': values, 'importance':importance, 'support':support})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3514b063-d80f-4c47-8180-d5674b2a76c7",
   "metadata": {},
   "source": [
    "The current [FeatureImportanceSummarizer](https://thisnotthat.readthedocs.io/en/latest/plotsummarypane_feature_importance.html) doesn't take sparse matrices as input.  As such we grabbed the class and modified it to suit our needs.  Again we'll integrate this back into the library later if it is generally useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7a2d6-0014-499f-a3c1-17a6c98e42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "class SparseFeatureImportanceSummarizer:\n",
    "    \"\"\"\n",
    "    Summarizer for the PlotSummaryPane that constructs a class balanced, L1 penalized,\n",
    "    logistic regression between the selected points and the remaining data.\n",
    "\n",
    "    This version takes a sparse feature matrix and column_index_dictionary which maps from the\n",
    "    indices of the matrix to the set of feature names.\n",
    "\n",
    "    Then it displays that feature importance in a bar plot.\n",
    "    The title is colour coded by model accuracy in order to give a rough approximation of\n",
    "    how much trust you should put in the model.\n",
    "\n",
    "    All of the standard caveats with using the coefficients of a linear model as a feature\n",
    "    importance measure should be included here.\n",
    "\n",
    "    It might be worth reading the sklearn documentation on the\n",
    "    common pitfalls in the interpretation of coefficients of linear models\n",
    "    (https://scikit-learn.org/stable/auto_examples/inspection/plot_linear_model_coefficient_interpretation.html)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data: sparse_matrix\n",
    "        A sparse_matrix corresponding to the plot points.\n",
    "    column_index_dictionary: dict\n",
    "        A dictionary mapping from column indices to column names\n",
    "    max_features: int <default: 15>\n",
    "        The maximum number of features to display the importance for.\n",
    "    tol_importance_relative: float <default: 0.01>\n",
    "        The minimum feature coefficient value in order to be considered important.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        column_index_dictionary,\n",
    "        max_features: int = 15,\n",
    "        tol_importance_relative: float = 0.01,\n",
    "    ):\n",
    "\n",
    "        self.data = data  # Indexed 0 to length.\n",
    "        self.max_features = max_features\n",
    "        self.tol_importance_relative = tol_importance_relative\n",
    "        self._features = column_index_dictionary\n",
    "        self._classifier = None\n",
    "        self._classes = None\n",
    "\n",
    "    def summarize(self, selected, width: int = 600, height: int = 600):\n",
    "        classes = np.zeros((self.data.shape[0],), dtype=\"int32\")\n",
    "        classes[selected] = True\n",
    "        classifier = LogisticRegression(\n",
    "            penalty=\"l1\", solver=\"liblinear\", class_weight=\"balanced\"\n",
    "        ).fit(self.data, classes)\n",
    "        self._classifier = classifier\n",
    "        self._classes = classes\n",
    "        assert classifier.coef_.shape[0] == 1 or classifier.coef_.ndim == 1\n",
    "        importance = np.squeeze(classifier.coef_)\n",
    "        index_importance = np.argsort(-np.abs(importance))[: self.max_features]\n",
    "        importance_abs = np.abs(importance)[index_importance]\n",
    "        importance_relative = importance_abs / np.max(importance_abs)\n",
    "        importance_restricted = importance[\n",
    "            np.where(importance_relative > self.tol_importance_relative)\n",
    "        ]\n",
    "\n",
    "        selected_columns_tuples = [self._features[x] for x in index_importance[: len(importance_restricted)] ]\n",
    "        selected_columns = [f\"{kind}: {value}\" for kind, value in selected_columns_tuples]\n",
    "\n",
    "        model_acc = classifier.score(self.data, classes)\n",
    "        fig = bpl.figure(\n",
    "            y_range=selected_columns,\n",
    "            width=width,\n",
    "            height=height,\n",
    "        )\n",
    "        if model_acc > 0.9:\n",
    "            fig.title = f\"Estimated Feature Importance\\nTrustworthiness high ({model_acc:.4} mean accuracy)\"\n",
    "            fig.title.text_color = \"green\"\n",
    "        elif model_acc > 0.8:\n",
    "            fig.title = f\"Estimated Feature Importance\\nTrustworthiness medium ({model_acc:.4} mean accuracy)\"\n",
    "            fig.title.text_color = \"yellow\"\n",
    "        elif model_acc > 0.5:\n",
    "            fig.title = f\"Estimated Feature Importance\\nTrustworthiness low ({model_acc:.4} mean accuracy)\"\n",
    "            fig.title.text_color = \"orange\"\n",
    "        else:\n",
    "            fig.title = f\"Estimated Feature Importance\\nTrustworthiness low ({model_acc:.4} mean accuracy)\"\n",
    "            fig.title.text_color = \"red\"\n",
    "\n",
    "        fig.hbar(\n",
    "            y=selected_columns,\n",
    "            right=importance[index_importance[: len(importance_restricted)]],\n",
    "            height=0.8,\n",
    "        )\n",
    "        plt.xlabel(\"Coefficient values corrected by the feature's std dev\")\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f202578-f4ca-4e11-8e30-c2fc218093a5",
   "metadata": {},
   "source": [
    "Explor the most frequent labels to find interesting ways to subset our data for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c706d95-3b34-4eb3-998e-c0fcb3acf6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(processes_top12[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2399310-73db-4525-a7b0-412336c3fb55",
   "metadata": {},
   "source": [
    "Perhaps we only want to study particular labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419aa84-5f82-4f52-b2c6-5ac1407c8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_of_interest = labels.loc[labels[\"label\"] == 'C:\\\\Windows\\\\SYSTEM32\\\\cmd.exe /c \"C:\\\\ncr\\\\DeleteArchiveSecurity.bat\"'].index\n",
    "process_map_study = process_map[indices_of_interest, :]\n",
    "process_map_study.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "120b0ab5-890f-4337-a0d3-94195962af9d",
   "metadata": {},
   "source": [
    "plot = tnt.BokehPlotPane(process_map_study, width=900, height=900, show_legend=False)\n",
    "editor = tnt.LabelEditorWidget([])\n",
    "editor.link_to_plot(plot)\n",
    "pn.Row(plot, editor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f571c3-2925-4c3d-8827-3bc60fc7453e",
   "metadata": {},
   "source": [
    "### Let's perform a more detailed exploration on the 12 most frequent labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0fb73d-7f8d-4200-93c2-60d606369aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_top12_ = set(processes_top12[\"label\"])\n",
    "labels_top12 = labels[[\"process_id\"]].copy()\n",
    "labels_top12[\"label\"] = labels[\"label\"].apply(lambda lb: lb if lb in labels_top12_ else \"(other)\")\n",
    "labels_top12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288f3b4-7b37-4dbd-92da-6cf698e1a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_top12_only = labels_top12.loc[labels_top12[\"label\"] != \"(other)\"]\n",
    "indices_of_interest = labels_top12_only.index\n",
    "process_map_top12_only = process_map[indices_of_interest, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f110ba0b-dac5-4750-8db5-627289223e63",
   "metadata": {},
   "source": [
    "Build a few matrices and column dictionary for helping us summarize our various selections of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040362f-62ab-4381-9809-6225b108810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_index_dictionary = {x:y[1] for x,y in enumerate(col2token)}\n",
    "sparse_features_top12_only = reduced_matrix[indices_of_interest,:]\n",
    "infoweight_matrix = vzt.InformationWeightTransformer().fit_transform(reduced_matrix[indices_of_interest,:]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7514e138-16ce-47d3-b49d-e7053f5d1fdb",
   "metadata": {},
   "source": [
    "Subselect the rows that we are interested and fold together the various bits of metadata associated with these processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a0456-5524-4228-a94c-58b94b019169",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_process_summary = CategoricalColumnTransformer(object_column_name='process_id', descriptor_column_name=list(metadata_pruned.columns[2:]), include_column_name=True).fit_transform(metadata_pruned.astype('str'))\n",
    "simple_process_summary = simple_process_summary.reset_index()\n",
    "simple_process_summary.columns = ['process_id', 'event_summary']\n",
    "metadata_pruned_top12 = metadata_pruned.iloc[indices_of_interest]\n",
    "metadata_pruned_top12 = pd.merge(metadata_pruned_top12, simple_process_summary, how='left')\n",
    "metadata_pruned_top12 = pd.merge(metadata_pruned_top12, labels_top12_only, how='left')\n",
    "metadata_pruned_top12['event_summary_string'] = [\"<br>\".join(x) for x in metadata_pruned_top12.event_summary]\n",
    "metadata_pruned_top12['freq'] = 1\n",
    "metadata_pruned_top12.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b4621-3a3f-47e8-b4a7-86fc442f88ca",
   "metadata": {},
   "source": [
    "Construct a custom data map explorer that is tailored to our data for helping us both explore and label processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac197d93-411d-4507-87b7-227e6be679b5",
   "metadata": {},
   "source": [
    "### Build ThisNotThat dashboard\n",
    "This code constructs an interactive dashboard for visualizingand exploring the our selected HBS data of interest it depends on a few objects to better summarize our embedding.  I'll include a list of the objects that are used below in case you'd like to apply a similar dashboard to your data.\n",
    "\n",
    "* ```process_map_top12_only```: This is an n by 2 numpy array that corresponds to x,y coordinates of our data.  In this case it is generated by UMAP\n",
    "* ```labels_top12_only``` is a pandas data frame with n rows.  It has a label column with a label per data point that we'll use for hovering over and passing to a ValueCountsSummarizer for displaying what points have been selected.\n",
    "* ```metadata_pruned_top12``` is a pandas data frame with n rows and all the various bits of metadata we might want to use to summarize our processes.\n",
    "* ```metadata_pruned.iloc[indices_of_interest]``` in order to align with our process_map_top12_only.\n",
    "* ```sparse_features_top12_only``` is a scipy sparse matrix with one row corresponding to each of our processes and one column associated with each of our tokens.\n",
    "* ```column_index_dictionary``` is a dictionary mapping between integers representing column ids and strings representing the feature associated with each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3286c597-e0cb-4c40-8eb7-d45e0a0992a0",
   "metadata": {},
   "source": [
    "Build a label annotation layer.  This particular annotation layer requires a high dimensional dense process embedding which we will generate via an informationWeightTransform of our Ngram matrix followed by a TruncatedSVD to find a 1024 dimensional dense representation.  It also requires our data map (```process_map_top12_only```) and our sparse representation (```sparse_features_top12_only```) along with it's column labels (```trimmed_path_dict```).  We'll use the trimmed paths of our features to avoid cluttering our data map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0de75d-212c-48f8-8fc2-c7dffb2a6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_path_dict = {i:(kind, value.split(\"\\\\\")[-1]) for i, (kind, value) in enumerate(col2token)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffbe1c2-d7a1-401a-aaa7-d720714b44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dense_vectors = TruncatedSVD(n_components=1024).fit_transform(infoweight_matrix)\n",
    "label_layer = tnt.SparseMetadataLabelLayers(dense_vectors, process_map_top12_only, sparse_features_top12_only, {i: value for i, (_, value) in trimmed_path_dict.items()}, cluster_map_representation=False, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa102c1-6746-4b0f-b42d-9c9a433a6e35",
   "metadata": {},
   "source": [
    "Now we'll construct a makrdown template which will leverage fields in our metadata data frame (```metadata_pruned_top12```) to give a detailed description of our process.  More advanced users might want to include a hyperlink to a more powerful process exploration tool or to simply include the entire event list in this markdown description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffe3566-1d7c-4c22-909f-4d0b588b1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "# {label}\n",
    "\n",
    "## {process_id}\n",
    "\n",
    "---\n",
    "\n",
    "{event_summary_string}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d5b77-3858-4bb4-b61b-2d61b5a169c2",
   "metadata": {},
   "source": [
    "Finally we will build our basic plot and it's various exploratory widgets to help us analyse and label our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3c202-cdb0-4240-8594-40f685f1e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = tnt.BokehPlotPane(process_map_top12_only, labels=labels_top12_only[\"label\"], width=800, height=800, show_legend=False, tools=\"pan,wheel_zoom,lasso_select,tap,reset\")\n",
    "editor = tnt.LabelEditorWidget(plot.labels, selectable_legend=True)\n",
    "editor.link_to_plot(plot)\n",
    "plot.add_cluster_labels(label_layer, max_text_size=24)\n",
    "\n",
    "info_pane = tnt.InformationPane(metadata_pruned_top12, markdown_template=template, width=600)\n",
    "info_pane.link_to_plot(plot)\n",
    "\n",
    "value_summarizer = tnt.summary.dataframe.ValueCountsSummarizer(labels_top12_only[\"label\"])\n",
    "value_summary_plot = tnt.summary.dataframe.DataSummaryPane(value_summarizer)\n",
    "value_summary_plot.link_to_plot(plot)\n",
    "\n",
    "metadata_pruned['freq'] = 1\n",
    "time_summarizer = tnt.summary.plot.TimeSeriesSummarizer(metadata_pruned_top12, time_column='timestamp', count_column='freq')\n",
    "time_summary_plot = tnt.summary.plot.PlotSummaryPane(time_summarizer)\n",
    "time_summary_plot.link_to_plot(plot)\n",
    "\n",
    "control_df = metadata_pruned_top12[\"THREAD,FLOW,PROCESS,FILE,REGISTRY,TASK,MODULE,USER_SESSION,SERVICE,SHELL,HOST\".split(',')]\n",
    "control = tnt.PlotControlWidget(raw_dataframe=control_df)\n",
    "control.link_to_plot(plot)\n",
    "\n",
    "support_summarizer = SparseSupportSummarizer(sparse_features_top12_only, trimmed_path_dict, max_features=10)\n",
    "support_summary_df = tnt.summary.dataframe.DataSummaryPane(support_summarizer, width=600, sizing_mode=None)\n",
    "support_summary_df.link_to_plot(plot)\n",
    "\n",
    "# info_summarizer = SparseSupportSummarizer(infoweight_matrix, trimmed_path_dict, max_features=10)\n",
    "# info_summary_df = tnt.summary.dataframe.DataSummaryPane(info_summarizer, width=400, sizing_mode='stretch_width')\n",
    "# info_summary_df.link_to_plot(plot)\n",
    "\n",
    "#This can be a bit expensive for large selections.  That can cause a lag especially when you use a search widget in conjunction with this widget being present.\n",
    "feature_summarizer = SparseFeatureImportanceSummarizer(sparse_features_top12_only, trimmed_path_dict, max_features=6)\n",
    "feature_summary_plot = tnt.summary.plot.PlotSummaryPane(feature_summarizer, width=800, height=400, sizing_mode=\"stretch_both\")\n",
    "feature_summary_plot.link_to_plot(plot)\n",
    "\n",
    "#This is one of our most simple search widgets.  Please see our read the docs page for more powerful and flexible search options.\n",
    "search = tnt.KeywordSearchWidget(labels_top12_only[\"label\"])\n",
    "search.link_to_plot(plot)\n",
    "\n",
    "#Lay out the widgets that you are interested in using via Panels excellent Row, Column and Tab functions\n",
    "# pn.Row(plot, editor, pn.Tabs((\"search\", pn.Column(search, time_summary_plot, value_summary_plot, )), (\"support\", pn.Column(support_summary_df, info_summary_df)), (\"feature importance\", feature_summary_plot), ('control', control), (info_pane)))\n",
    "pn.Column(\n",
    "    pn.Row(plot, pn.Column(search, pn.Row(editor, control))),\n",
    "    pn.Tabs(\n",
    "        (\"Chronology\", pn.Row(time_summary_plot, value_summary_plot)),\n",
    "        # (\"Support\", pn.Row(support_summary_df, info_summary_df)),\n",
    "        (\"Feature importance\", pn.Row(feature_summary_plot, support_summary_df)),\n",
    "        (\"Details\", info_pane))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d497f1-d546-46f3-a879-5f08acb68292",
   "metadata": {},
   "source": [
    "Ready for demos of exploring the map contents using summarizers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scipy 2023",
   "language": "python",
   "name": "scipy2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
